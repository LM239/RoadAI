{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Algorithm to detect both load and dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataloader\n",
    "from pydantic import BaseModel\n",
    "import typing\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "import geopy.distance\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from schemas import Machine, Position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = '04-27-2023' #DD-MM-YYYY\n",
    "machine_type = 'Truck'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class setting parameters determining when we predict load/dump\n",
    "\n",
    "class criteria(BaseModel):\n",
    "    optimal_K: int = 50                     # Nb of clusters for work areas\n",
    "    meters_from_area: int = 30              # Radius from a cluster center\n",
    "    seconds_for_vector: int = 10            # \"Length\" of vector used to determine if vehicle is reversing\n",
    "    \n",
    "    speed_limit: int = 30                   # Cannot be loading or dumping if speed higher than this. Don't like such a high number.\n",
    "    meters_since_last_activity: int = 500   # Meters driven since last load/dump\n",
    "    \n",
    "    minutes_load: int = 3                   # Look at distance driven last x minutes before a possible load\n",
    "    max_sum_last_x_minutes_load: int = 1000 # Max meters driven during the last x minutes\n",
    "    minutes_dump: int = 3                   # Look at distance driven last x minutes before a possible load\n",
    "    max_sum_last_x_minutes_dump: int = 1000 # Max meters driven during the last x minutes\n",
    "    \n",
    "    inner_prod_threshold: float = 0.80      # A threshold to pick up possible reversal\n",
    "\n",
    "criterias = criteria()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n",
      "Could not add row, row was type:  <class 'float'>  but expected ndarray.\n"
     ]
    }
   ],
   "source": [
    "day = '04-27-2023' #DD-MM-YYYY\n",
    "machine_type = 'Truck'\n",
    "#Loading gps data for selected day and day before\n",
    "trip = dataloader.TripsLoader(day)\n",
    "\n",
    "#Use previous day data to create clustering\n",
    "\n",
    "# Convert the date string to a datetime object\n",
    "date_obj = datetime.strptime(day, \"%m-%d-%Y\")\n",
    "# Subtract one day using timedelta\n",
    "new_date = date_obj - timedelta(days=1)\n",
    "# Format the new date back to the desired format\n",
    "day_before = new_date.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "trip_day_before = dataloader.TripsLoader(day_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_load_dump_clusters():\n",
    "    all_load_positions_for_day_before = []\n",
    "    all_dump_positions_for_day_before = []\n",
    "    for machine_number in trip_day_before._machines.keys():\n",
    "        temp_machine = trip_day_before._machines[machine_number]\n",
    "        if temp_machine.machine_type == machine_type:\n",
    "            all_load_positions_for_day_before.append([trip.load_latlon for trip in temp_machine.trips])\n",
    "            all_dump_positions_for_day_before.append([trip.dump_latlon for trip in temp_machine.trips])\n",
    "\n",
    "    all_load_positions_for_day_before =  [item for sublist in all_load_positions_for_day_before for item in sublist]\n",
    "    all_dump_positions_for_day_before = [item for sublist in all_dump_positions_for_day_before for item in sublist]\n",
    "\n",
    "    # Assuming 'coordinates' is list of tuples [(lat1, lon1), (lat2, lon2), ...]\n",
    "    load_coordinates_array = np.array(all_load_positions_for_day_before)\n",
    "    dump_coordinates_array = np.array(all_dump_positions_for_day_before)\n",
    "\n",
    "    # Fit the KMeans model with the optimal K value\n",
    "    load_kmeans = KMeans(n_clusters=criterias.optimal_K, random_state=42, n_init='auto')\n",
    "    dump_kmeans = KMeans(n_clusters=criterias.optimal_K, random_state=42, n_init='auto')\n",
    "    load_kmeans.fit(load_coordinates_array)\n",
    "    dump_kmeans.fit(dump_coordinates_array)\n",
    "\n",
    "    # Get the coordinates of the cluster centers for the optimal K value\n",
    "    load_cluster_centers = load_kmeans.cluster_centers_\n",
    "    dump_cluster_centers = dump_kmeans.cluster_centers_\n",
    "\n",
    "    return load_cluster_centers, dump_cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the coordinates of the cluster centers\n",
    "load_cluster_centers, dump_cluster_centers = generate_load_dump_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class points_times(BaseModel):\n",
    "    points: list[tuple[float, float]] = []\n",
    "    times: list[datetime] = []\n",
    "\n",
    "class predicted_load_dump(BaseModel):\n",
    "    load: points_times = points_times()\n",
    "    dump: points_times = points_times()\n",
    "\n",
    "class stats(BaseModel): #Represents actual data\n",
    "    all_positions: list[Position] = []  # Positions recorded during a day\n",
    "    load: points_times = points_times() # Load points and times\n",
    "    dump: points_times = points_times() # Dump points and times\n",
    "    day_speeds: list[float] = []        # Speeds\n",
    "    day_dists: list[float] = []         # Distances between each recording\n",
    "    day_times: list[datetime] = []      # Timestamp for two above lists\n",
    "    inner_prods: list[float] = []       # Inner product of consecutive normalized driving vectors\n",
    "\n",
    "\n",
    "class automated_load_dump_for_machine():\n",
    "\n",
    "    def __init__(self, \n",
    "                 machine_data: Machine): \n",
    "                #  load_cluster_centers: typing.Any,# Both should be list[tuple[float, float]], should implement \n",
    "                #  dump_cluster_centers: typing.Any) -> None:\n",
    "        \n",
    "        self.machine = machine_data\n",
    "        self.predicted = predicted_load_dump()\n",
    "        self.stats = stats()\n",
    "\n",
    "        all_pos = [trips.positions for trips in self.machine.trips]\n",
    "        self.stats.all_positions = [item for sublist in all_pos for item in sublist]\n",
    "        self.stats.load.points = [trips.load_latlon for trips in self.machine.trips]\n",
    "        self.stats.load.times = [trips.positions[0].timestamp for trips in self.machine.trips]\n",
    "        self.stats.dump.points = [trips.dump_latlon for trips in self.machine.trips]\n",
    "        \n",
    "        actual_dump_times = []\n",
    "        for t in self.machine.trips:        #Not pretty, because we don't have dump time in trip info by default\n",
    "            temp_dump_laton = t.dump_latlon # Must match latlons\n",
    "            for position in t.positions:\n",
    "                if temp_dump_laton == (position.lat, position.lon):\n",
    "                    actual_dump_times.append(position.timestamp)\n",
    "                    break\n",
    "        self.stats.dump.times = actual_dump_times\n",
    "\n",
    "        # self.load_cluster_centers = load_cluster_centers\n",
    "        # self.dump_cluster_centers = dump_cluster_centers\n",
    "\n",
    "        #These four lines should be rewritten, to a class or something\n",
    "        self.entering_load_working_area = []\n",
    "        self.exiting_load_working_area = []\n",
    "        self.entering_dump_working_area = []\n",
    "        self.exiting_dump_working_area = []\n",
    "        self.in_dumping_area: list[int | bool] = []\n",
    "        self.in_loading_area: list[int | bool] = []\n",
    "        self.meters_from_last_act = []\n",
    "\n",
    "    def predict(self):\n",
    "\n",
    "        #We know first loading because that is when data begins\n",
    "        self.predicted.load.points.append((self.stats.all_positions[0].lat, self.stats.all_positions[0].lon))\n",
    "        self.predicted.load.times.append(self.stats.all_positions[0].timestamp)\n",
    "\n",
    "        #When true, we are predicting load, else dump. Next prediction will be dump, since we have load above\n",
    "        predicting_load = False\n",
    "\n",
    "        #Initialize variables that keep track of whether or not we are in a usual area for loading or dumping\n",
    "        #As given by load and dump clusters and criterias.meters_from_area\n",
    "        in_load_working_area = False #Probably true, since first position is when loading\n",
    "        in_dump_working_area = False #Maybe false, since first position is when loading\n",
    "\n",
    "        \n",
    "        #We determine the true value of the two above variables\n",
    "        # for coord in self.load_cluster_centers:  #But verify with created clusters of load points from day before\n",
    "        #         if geopy.distance.geodesic(coord, (self.stats.all_positions[0].lat, self.stats.all_positions[0].lon)).m < criterias.meters_from_area:\n",
    "        #             in_load_working_area = True\n",
    "        #             self.in_loading_area.append(1)\n",
    "        #         else:\n",
    "        #             self.in_loading_area.append(0)\n",
    "\n",
    "        # for coord in self.dump_cluster_centers: #But verify with created clusters of load points from day before\n",
    "        #         if geopy.distance.geodesic(coord, (self.stats.all_positions[0].lat, self.stats.all_positions[0].lon)).m < criterias.meters_from_area:\n",
    "        #             in_dump_working_area = True\n",
    "        #             self.in_dumping_area.append(1)\n",
    "        #         else:\n",
    "        #             self.in_dumping_area.append(0)\n",
    "\n",
    "        \n",
    "\n",
    "        #We keep track of how many meters we have driven since last dump or load    \n",
    "        meters_since_last_activity = 0\n",
    "        \n",
    "        #We start predicting. Are going to iterate over all positions, from first to last\n",
    "        for i in range(1,len(self.stats.all_positions[1:])+1):\n",
    "            \n",
    "            current_pos = self.stats.all_positions[i]\n",
    "            prev_pos = self.stats.all_positions[i-1]\n",
    "\n",
    "            #Seconds passed since last timestamp\n",
    "            seconds_gone = (current_pos.timestamp.to_pydatetime()-prev_pos.timestamp.to_pydatetime()).total_seconds()\n",
    "            if seconds_gone <= 0:\n",
    "                # self.stats.day_speeds.append(self.stats.day_speeds[-1])\n",
    "                # self.stats.inner_prods.append(self.stats.inner_prods[-1])\n",
    "                # # self.stats.inner_prods.append(self.stats.inner_prods[-1])\n",
    "                # self.stats.day_times.append(self.stats.day_times[-1])\n",
    "\n",
    "                # just add some unique value so that we can remove these duplicate rows later\n",
    "                self.stats.day_speeds.append(np.nan)\n",
    "                self.stats.inner_prods.append(np.nan)\n",
    "                # self.stats.inner_prods.append(self.stats.inner_prods[-1])\n",
    "                self.stats.day_times.append(self.stats.day_times[-1])\n",
    "                self.meters_from_last_act.append(np.nan)\n",
    "            if seconds_gone > 0:\n",
    "\n",
    "                #Meters driven since last timestamp\n",
    "                meters_driven = geopy.distance.geodesic((current_pos.lat, current_pos.lon), (prev_pos.lat, prev_pos.lon)).m\n",
    "                \n",
    "                meters_since_last_activity += meters_driven\n",
    "                # if we have either load or dump, distance from last activity is set to 0\n",
    "                \n",
    "                if (self.stats.all_positions[i].lat, self.stats.all_positions[i].lon) in self.stats.load.points:\n",
    "                    meters_since_last_activity=0\n",
    "                    \n",
    "                    \n",
    "                self.meters_from_last_act.append(meters_since_last_activity/1000) # km\n",
    "\n",
    "                #Meters driven since last timestamp\n",
    "                speed_kmh = (meters_driven/seconds_gone)*3.6\n",
    "\n",
    "                #Add the speed to a list for entire day\n",
    "                self.stats.day_speeds.append(speed_kmh)\n",
    "\n",
    "                #Add the distance (km) between the two timestamps \n",
    "                self.stats.day_dists.append(meters_driven/1000)\n",
    "\n",
    "                #Add the timestamp for the two above values\n",
    "                self.stats.day_times.append(current_pos.timestamp)\n",
    "\n",
    "                #Compute vectors. This is a lot of code, maybe create some function?\n",
    "                #Create vector for computing reverse of vehicle\n",
    "                vector_start = current_pos.timestamp-timedelta(seconds=criterias.seconds_for_vector)\n",
    "                index_start_vector = 0\n",
    "                for j, ts in enumerate(self.stats.day_times):\n",
    "                    if ts >= vector_start:\n",
    "                        index_start_vector = j\n",
    "                        break\n",
    "                \n",
    "                current_vector = [self.stats.all_positions[i].lat-self.stats.all_positions[i-3].lat,\n",
    "                                    self.stats.all_positions[i].lon-self.stats.all_positions[i-3].lon]\n",
    "                prev_vector = [self.stats.all_positions[index_start_vector].lat-self.stats.all_positions[index_start_vector-3].lat,\n",
    "                                self.stats.all_positions[index_start_vector].lon-self.stats.all_positions[index_start_vector-3].lon]\n",
    "\n",
    "                current_vector_norm = current_vector/np.linalg.norm(current_vector)\n",
    "                prev_vector_norm = prev_vector/np.linalg.norm(prev_vector)\n",
    "                inner_product = np.inner(current_vector_norm,prev_vector_norm)\n",
    "                self.stats.inner_prods.append(inner_product)\n",
    "            \n",
    "                #Check if we are currently in a loading or dumping working area\n",
    "                #If yes, we update value\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                # currently_in_load_working_area = False\n",
    "                # for coord in self.load_cluster_centers:\n",
    "                #     if geopy.distance.geodesic(coord, (current_pos.lat, current_pos.lon)).m < criterias.meters_from_area:\n",
    "                #         currently_in_load_working_area = True\n",
    "                \n",
    "                # currently_in_dump_working_area = False\n",
    "                # for coord in self.dump_cluster_centers:\n",
    "                #     if geopy.distance.geodesic(coord, (current_pos.lat, current_pos.lon)).m < criterias.meters_from_area:\n",
    "                #         currently_in_dump_working_area = True\n",
    "\n",
    "                # #Could be interesting to mark where we enter and exit load and dump zones. Can be done with this code.\n",
    "                # #Can be used for plotting, see notebooks for examples    \n",
    "                # if not in_load_working_area and currently_in_load_working_area:\n",
    "                #     self.entering_load_working_area.append(current_pos.timestamp)\n",
    "                #     in_load_working_area = True\n",
    "                # elif in_load_working_area and not currently_in_load_working_area:\n",
    "                #     self.exiting_load_working_area.append(current_pos.timestamp)\n",
    "                #     in_load_working_area = False\n",
    "\n",
    "                # if not in_dump_working_area and currently_in_dump_working_area:\n",
    "                #     self.entering_dump_working_area.append(current_pos.timestamp)\n",
    "                #     in_dump_working_area = True\n",
    "                # elif in_dump_working_area and not currently_in_dump_working_area:\n",
    "                #     self.exiting_dump_working_area.append(current_pos.timestamp)\n",
    "                #     in_dump_working_area = False\n",
    "\n",
    "                # #Logic for predicting loading point\n",
    "                # if speed_kmh < criterias.speed_limit and meters_since_last_activity>criterias.meters_since_last_activity:\n",
    "                #     if predicting_load:\n",
    "                #         if in_load_working_area:\n",
    "                #             last_min_start = current_pos.timestamp-timedelta(minutes=criterias.minutes_load)\n",
    "                #             index_start_minute = 0\n",
    "                    #         for i, ts in enumerate(self.stats.day_times):\n",
    "                    #             if ts >= last_min_start:\n",
    "                    #                 index_start_minute = i\n",
    "                    #                 break\n",
    "                    #         sum_over_last_minute = np.sum(self.stats.day_speeds[index_start_minute:])\n",
    "                            \n",
    "                    #         if sum_over_last_minute < criterias.max_sum_last_x_minutes_load:\n",
    "                    #             self.predicted.load.points.append((current_pos.lat, current_pos.lon))\n",
    "                    #             self.predicted.load.times.append(current_pos.timestamp)\n",
    "                                \n",
    "                    #             #Have now predicted a load, next dump\n",
    "                    #             predicting_load = False\n",
    "                    #             meters_since_last_activity = 0\n",
    "\n",
    "                    # else: #Predicting dump\n",
    "                    #     if in_dump_working_area:\n",
    "                    #         last_min_start = current_pos.timestamp-timedelta(minutes=criterias.minutes_dump)\n",
    "                    #         index_start_minute = 0\n",
    "                    #         for i, ts in enumerate(self.stats.day_times):\n",
    "                    #             if ts >= last_min_start:\n",
    "                    #                 index_start_minute = i\n",
    "                    #                 break\n",
    "                    #         sum_over_last_minute = np.sum(self.stats.day_speeds[index_start_minute:])\n",
    "                            \n",
    "                    #         if sum_over_last_minute < criterias.max_sum_last_x_minutes_dump and self.stats.inner_prods[-1] < criterias.inner_prod_threshold: #Not ideal, want to instead pick the best among times, not just the first viable option, but difficult with live tracking.\n",
    "                    #             self.predicted.dump.points.append((current_pos.lat, current_pos.lon))\n",
    "                    #             self.predicted.dump.times.append(current_pos.timestamp)\n",
    "                                \n",
    "                    #             #Have now predicted a dump, next load\n",
    "                    #             predicting_load = True\n",
    "                    #             meters_since_last_activity = 0\n",
    "\n",
    "    def get_df_with_ml_data(self):\n",
    "        load_times_set = set(self.stats.load.times)\n",
    "        dump_times_set = set(self.stats.dump.times)\n",
    "        positions = self.stats.all_positions\n",
    "        latitude = [sublist.lat for sublist in positions]\n",
    "        longitude = [sublist.lon for sublist in positions]\n",
    "        load = [time in load_times_set for time in self.stats.day_times]\n",
    "        dump = [time in dump_times_set for time in self.stats.day_times]\n",
    "        # print('len(speed) :', len(self.stats.day_speeds))\n",
    "        # print('len lon: ', len(longitude[:-1]))\n",
    "        # print('len lat:' , len(latitude[:-1]))\n",
    "        # print('inner prods', len(self.stats.inner_prods))\n",
    "        # print('Load', len(load))\n",
    "        # print('dump', len(dump))\n",
    "        # print('datetime', len(self.stats.day_times))\n",
    "        # print('machine id', self.machine.machine_id)\n",
    "        # print('meters from last act', len(self.meters_from_last_act[:-1]))\n",
    "        #  create Dataframe with the given variables\n",
    "        # we dont have the speed for the last datapoint as it uses forward derivative scheme\n",
    "        df = pd.DataFrame({\n",
    "            \"MachineID\": [self.machine.machine_id]*len(self.stats.day_times),\n",
    "            \"DateTime\": self.stats.day_times,\n",
    "            # \"Time_from_start\": [(time.min - self.stats.day_times[0].min) for time in self.stats.day_times],\n",
    "            \"Speed\": self.stats.day_speeds,\n",
    "            \"Inner_products\": self.stats.inner_prods,\n",
    "            \"Latitude\": latitude[:-1],\n",
    "            \"Longitude\": longitude[:-1],\n",
    "            \"km_from_last_event\": self.meters_from_last_act,\n",
    "            \"Load\": load,\n",
    "            \"Dump\": dump\n",
    "        })\n",
    "\n",
    "        \n",
    "        return df\n",
    "        # df.to_csv(f'data/ml_model_data/time_speed_{self.machine.machine_id}.csv', index=False, sep=',')\n",
    "\n",
    "        # # Save units to csv file\n",
    "        # units = pd.DataFrame({\n",
    "        #     \"DateTime\": [\"Datetime\"],\n",
    "        #     \"Time_from_start\": [\"Minutes\"],\n",
    "        #     \"Speed\": [\"km/h\"],\n",
    "        #     \"Inner_products\": [\"-\"],\n",
    "        #     \"Load\": [\"-\"],\n",
    "        #     \"Dump\": [\"-\"]\n",
    "        # })\n",
    "        # units.to_csv(f'data/ml_model_data/units_{self.machine.machine_id}.csv', index=False, sep=',')\n",
    "\n",
    "    \n",
    "    def time_plot(self):\n",
    "\n",
    "        # Plots, not wanted when a lot of data\n",
    "        # Create subplots with 2 rows and 1 column\n",
    "        fig = make_subplots(rows=3, cols=1, shared_xaxes=True, vertical_spacing=0.1)\n",
    "\n",
    "        # Add the first line plot to the first subplot\n",
    "        \n",
    "        fig.add_trace(go.Scatter(x=self.stats.day_times, y=self.stats.day_speeds, mode='lines', name='Speed'), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.stats.load.times, y=[0 for a in self.stats.load.times], mode='markers', marker=dict(symbol='cross', size=10, color='red'), name='Load actual'), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.predicted.load.times, y=[0 for p in self.predicted.load.times], mode='markers', marker=dict(symbol='star', size=10, color='red'), name='Load predicted'), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.stats.dump.times, y=[0 for a in self.stats.dump.times], mode='markers', marker=dict(symbol='cross', size=10, color='green'), name='Dump actual'), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.predicted.dump.times, y=[0 for p in self.predicted.dump.times], mode='markers', marker=dict(symbol='star', size=10, color='green'), name='Dump predicted'), row=1, col=1)\n",
    "\n",
    "        # Add the second line plot to the second subplot\n",
    "        fig.add_trace(go.Scatter(x=self.stats.day_times, y=np.cumsum(self.stats.day_dists), mode='lines', name='Cumulative distance'), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.stats.load.times, y=[0 for a in self.stats.load.times], mode='markers', marker=dict(symbol='cross', size=10, color='red'), name='Load actual'), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.predicted.load.times, y=[0 for p in self.predicted.load.times], mode='markers', marker=dict(symbol='star', size=10, color='red'), name='Load predicted'), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.stats.dump.times, y=[0 for a in self.stats.dump.times], mode='markers', marker=dict(symbol='cross', size=10, color='green'), name='Dump actual'), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=self.predicted.dump.times, y=[0 for p in self.predicted.dump.times], mode='markers', marker=dict(symbol='star', size=10, color='green'), name='Dump predicted'), row=2, col=1)\n",
    "\n",
    "        # Add the third line plot\n",
    "        fig.add_trace(go.Scatter(x=self.stats.day_times, y=self.stats.inner_prods, mode='lines', name='Inner product of vectors'), row=3, col=1)\n",
    "\n",
    "        # Update layout settings for both subplots\n",
    "        fig.update_layout(title=str('Subplots of Speeds and cumulative distance, machine_id: '+ str(self.machine.machine_id)),\n",
    "                        xaxis_title='Timestamp',\n",
    "                        showlegend=True)\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "    def gantt_plot(self):\n",
    "\n",
    "        #Actual trips\n",
    "        all_trips_for_machine = self.machine.trips\n",
    "        start_end_each_trip_dict_actual = [dict(Start=trips.start_date, End=trips.end_date, Load=trips.load, Dist=trips.length, Id=trips.trip_id) for trips in all_trips_for_machine]\n",
    "        df_pyplot_actual = pd.DataFrame(start_end_each_trip_dict_actual)\n",
    "        \n",
    "        \n",
    "        #Predicted trips\n",
    "        start_end_each_trip_dict_predicted = [dict(Start=self.predicted.load.times[i], End=self.predicted.load.times[i+1]) for i in range(len(self.predicted.load.times)-1)]\n",
    "        df_pyplot_predicted = pd.DataFrame(start_end_each_trip_dict_predicted)\n",
    "\n",
    "        fig = px.timeline(df_pyplot_actual, x_start=\"Start\", x_end=\"End\", custom_data=[\"Load\", \"Dist\", \"Id\"])\n",
    "        fig.update_traces(\n",
    "            hovertemplate=\"<br>\".join([\n",
    "                \"Start: %{base}\",\n",
    "                \"End: %{x}\",\n",
    "                \"Load: %{customdata[0]}\",\n",
    "                \"Distance: %{customdata[1]}\",\n",
    "                \"ID: %{customdata[2]}\"\n",
    "            ])\n",
    "        )\n",
    "        fig.update_yaxes(autorange=\"reversed\") # otherwise tasks are listed from the bottom up\n",
    "        fig.show()\n",
    "\n",
    "        fig = px.timeline(df_pyplot_predicted, x_start=\"Start\", x_end=\"End\")\n",
    "        fig.update_traces(\n",
    "            hovertemplate=\"<br>\".join([\n",
    "                \"Start: %{base}\",\n",
    "                \"End: %{x}\"\n",
    "            ])\n",
    "        )\n",
    "        fig.update_yaxes(autorange=\"reversed\") # otherwise tasks are listed from the bottom up\n",
    "        fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# day = '04-27-2023' #DD-MM-YYYY\n",
    "# machine_type = 'Truck'\n",
    "# #Loading gps data for selected day and day before\n",
    "# trip = dataloader.TripsLoader(day)\n",
    "\n",
    "#Use previous day data to create clustering\n",
    "\n",
    "# Convert the date string to a datetime object\n",
    "# date_obj = datetime.strptime(day, \"%m-%d-%Y\")\n",
    "# # Subtract one day using timedelta\n",
    "# new_date = date_obj - timedelta(days=1)\n",
    "# # Format the new date back to the desired format\n",
    "# day_before = new_date.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# trip_day_before = dataloader.TripsLoader(day_before)\n",
    "# # Get the coordinates of the cluster centers\n",
    "# load_cluster_centers, dump_cluster_centers = generate_load_dump_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(trip._machines.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(speed) : 11924\n",
      "len lon:  11924\n",
      "len lat: 11924\n",
      "inner prods 11924\n",
      "Load 11924\n",
      "dump 11924\n",
      "datetime 11924\n",
      "machine id 20\n",
      "meters from last act 11923\n",
      "len(speed) : 12582\n",
      "len lon:  12582\n",
      "len lat: 12582\n",
      "inner prods 12582\n",
      "Load 12582\n",
      "dump 12582\n",
      "datetime 12582\n",
      "machine id 13\n",
      "meters from last act 12581\n",
      "len(speed) : 10760\n",
      "len lon:  10760\n",
      "len lat: 10760\n",
      "inner prods 10760\n",
      "Load 10760\n",
      "dump 10760\n",
      "datetime 10760\n",
      "machine id 25\n",
      "meters from last act 10759\n",
      "len(speed) : 8575\n",
      "len lon:  8575\n",
      "len lat: 8575\n",
      "inner prods 8575\n",
      "Load 8575\n",
      "dump 8575\n",
      "datetime 8575\n",
      "machine id 11\n",
      "meters from last act 8574\n",
      "len(speed) : 10135\n",
      "len lon:  10135\n",
      "len lat: 10135\n",
      "inner prods 10135\n",
      "Load 10135\n",
      "dump 10135\n",
      "datetime 10135\n",
      "machine id 46\n",
      "meters from last act 10134\n",
      "len(speed) : 9953\n",
      "len lon:  9953\n",
      "len lat: 9953\n",
      "inner prods 9953\n",
      "Load 9953\n",
      "dump 9953\n",
      "datetime 9953\n",
      "machine id 52\n",
      "meters from last act 9952\n",
      "len(speed) : 7867\n",
      "len lon:  7867\n",
      "len lat: 7867\n",
      "inner prods 7867\n",
      "Load 7867\n",
      "dump 7867\n",
      "datetime 7867\n",
      "machine id 15\n",
      "meters from last act 7866\n",
      "len(speed) : 9497\n",
      "len lon:  9497\n",
      "len lat: 9497\n",
      "inner prods 9497\n",
      "Load 9497\n",
      "dump 9497\n",
      "datetime 9497\n",
      "machine id 22\n",
      "meters from last act 9496\n",
      "len(speed) : 10937\n",
      "len lon:  10937\n",
      "len lat: 10937\n",
      "inner prods 10937\n",
      "Load 10937\n",
      "dump 10937\n",
      "datetime 10937\n",
      "machine id 26\n",
      "meters from last act 10936\n",
      "len(speed) : 9323\n",
      "len lon:  9323\n",
      "len lat: 9323\n",
      "inner prods 9323\n",
      "Load 9323\n",
      "dump 9323\n",
      "datetime 9323\n",
      "machine id 5\n",
      "meters from last act 9322\n",
      "len(speed) : 10942\n",
      "len lon:  10942\n",
      "len lat: 10942\n",
      "inner prods 10942\n",
      "Load 10942\n",
      "dump 10942\n",
      "datetime 10942\n",
      "machine id 44\n",
      "meters from last act 10941\n",
      "len(speed) : 10847\n",
      "len lon:  10847\n",
      "len lat: 10847\n",
      "inner prods 10847\n",
      "Load 10847\n",
      "dump 10847\n",
      "datetime 10847\n",
      "machine id 16\n",
      "meters from last act 10846\n",
      "len(speed) : 10039\n",
      "len lon:  10039\n",
      "len lat: 10039\n",
      "inner prods 10039\n",
      "Load 10039\n",
      "dump 10039\n",
      "datetime 10039\n",
      "machine id 30\n",
      "meters from last act 10038\n",
      "len(speed) : 9591\n",
      "len lon:  9591\n",
      "len lat: 9591\n",
      "inner prods 9591\n",
      "Load 9591\n",
      "dump 9591\n",
      "datetime 9591\n",
      "machine id 23\n",
      "meters from last act 9590\n",
      "len(speed) : 9596\n",
      "len lon:  9596\n",
      "len lat: 9596\n",
      "inner prods 9596\n",
      "Load 9596\n",
      "dump 9596\n",
      "datetime 9596\n",
      "machine id 1\n",
      "meters from last act 9595\n",
      "len(speed) : 8581\n",
      "len lon:  8581\n",
      "len lat: 8581\n",
      "inner prods 8581\n",
      "Load 8581\n",
      "dump 8581\n",
      "datetime 8581\n",
      "machine id 38\n",
      "meters from last act 8580\n",
      "len(speed) : 8531\n",
      "len lon:  8531\n",
      "len lat: 8531\n",
      "inner prods 8531\n",
      "Load 8531\n",
      "dump 8531\n",
      "datetime 8531\n",
      "machine id 24\n",
      "meters from last act 8530\n",
      "len(speed) : 7243\n",
      "len lon:  7243\n",
      "len lat: 7243\n",
      "inner prods 7243\n",
      "Load 7243\n",
      "dump 7243\n",
      "datetime 7243\n",
      "machine id 8\n",
      "meters from last act 7242\n",
      "len(speed) : 5900\n",
      "len lon:  5900\n",
      "len lat: 5900\n",
      "inner prods 5900\n",
      "Load 5900\n",
      "dump 5900\n",
      "datetime 5900\n",
      "machine id 4\n",
      "meters from last act 5899\n",
      "len(speed) : 5566\n",
      "len lon:  5566\n",
      "len lat: 5566\n",
      "inner prods 5566\n",
      "Load 5566\n",
      "dump 5566\n",
      "datetime 5566\n",
      "machine id 50\n",
      "meters from last act 5565\n",
      "len(speed) : 3115\n",
      "len lon:  3115\n",
      "len lat: 3115\n",
      "inner prods 3115\n",
      "Load 3115\n",
      "dump 3115\n",
      "datetime 3115\n",
      "machine id 49\n",
      "meters from last act 3114\n",
      "len(speed) : 6945\n",
      "len lon:  6945\n",
      "len lat: 6945\n",
      "inner prods 6945\n",
      "Load 6945\n",
      "dump 6945\n",
      "datetime 6945\n",
      "machine id 49\n",
      "meters from last act 6944\n",
      "len(speed) : 9663\n",
      "len lon:  9663\n",
      "len lat: 9663\n",
      "inner prods 9663\n",
      "Load 9663\n",
      "dump 9663\n",
      "datetime 9663\n",
      "machine id 13\n",
      "meters from last act 9662\n",
      "len(speed) : 9255\n",
      "len lon:  9255\n",
      "len lat: 9255\n",
      "inner prods 9255\n",
      "Load 9255\n",
      "dump 9255\n",
      "datetime 9255\n",
      "machine id 1\n",
      "meters from last act 9254\n",
      "len(speed) : 10860\n",
      "len lon:  10860\n",
      "len lat: 10860\n",
      "inner prods 10860\n",
      "Load 10860\n",
      "dump 10860\n",
      "datetime 10860\n",
      "machine id 40\n",
      "meters from last act 10859\n",
      "len(speed) : 10319\n",
      "len lon:  10319\n",
      "len lat: 10319\n",
      "inner prods 10319\n",
      "Load 10319\n",
      "dump 10319\n",
      "datetime 10319\n",
      "machine id 25\n",
      "meters from last act 10318\n",
      "len(speed) : 12931\n",
      "len lon:  12931\n",
      "len lat: 12931\n",
      "inner prods 12931\n",
      "Load 12931\n",
      "dump 12931\n",
      "datetime 12931\n",
      "machine id 20\n",
      "meters from last act 12930\n",
      "len(speed) : 9123\n",
      "len lon:  9123\n",
      "len lat: 9123\n",
      "inner prods 9123\n",
      "Load 9123\n",
      "dump 9123\n",
      "datetime 9123\n",
      "machine id 22\n",
      "meters from last act 9122\n",
      "len(speed) : 9528\n",
      "len lon:  9528\n",
      "len lat: 9528\n",
      "inner prods 9528\n",
      "Load 9528\n",
      "dump 9528\n",
      "datetime 9528\n",
      "machine id 52\n",
      "meters from last act 9527\n",
      "len(speed) : 11125\n",
      "len lon:  11125\n",
      "len lat: 11125\n",
      "inner prods 11125\n",
      "Load 11125\n",
      "dump 11125\n",
      "datetime 11125\n",
      "machine id 26\n",
      "meters from last act 11124\n",
      "len(speed) : 6709\n",
      "len lon:  6709\n",
      "len lat: 6709\n",
      "inner prods 6709\n",
      "Load 6709\n",
      "dump 6709\n",
      "datetime 6709\n",
      "machine id 46\n",
      "meters from last act 6708\n",
      "len(speed) : 8804\n",
      "len lon:  8804\n",
      "len lat: 8804\n",
      "inner prods 8804\n",
      "Load 8804\n",
      "dump 8804\n",
      "datetime 8804\n",
      "machine id 5\n",
      "meters from last act 8803\n",
      "len(speed) : 7431\n",
      "len lon:  7431\n",
      "len lat: 7431\n",
      "inner prods 7431\n",
      "Load 7431\n",
      "dump 7431\n",
      "datetime 7431\n",
      "machine id 11\n",
      "meters from last act 7430\n",
      "len(speed) : 8036\n",
      "len lon:  8036\n",
      "len lat: 8036\n",
      "inner prods 8036\n",
      "Load 8036\n",
      "dump 8036\n",
      "datetime 8036\n",
      "machine id 30\n",
      "meters from last act 8035\n",
      "len(speed) : 9395\n",
      "len lon:  9395\n",
      "len lat: 9395\n",
      "inner prods 9395\n",
      "Load 9395\n",
      "dump 9395\n",
      "datetime 9395\n",
      "machine id 15\n",
      "meters from last act 9394\n",
      "len(speed) : 9629\n",
      "len lon:  9629\n",
      "len lat: 9629\n",
      "inner prods 9629\n",
      "Load 9629\n",
      "dump 9629\n",
      "datetime 9629\n",
      "machine id 44\n",
      "meters from last act 9628\n",
      "len(speed) : 6972\n",
      "len lon:  6972\n",
      "len lat: 6972\n",
      "inner prods 6972\n",
      "Load 6972\n",
      "dump 6972\n",
      "datetime 6972\n",
      "machine id 38\n",
      "meters from last act 6971\n",
      "len(speed) : 9378\n",
      "len lon:  9378\n",
      "len lat: 9378\n",
      "inner prods 9378\n",
      "Load 9378\n",
      "dump 9378\n",
      "datetime 9378\n",
      "machine id 24\n",
      "meters from last act 9377\n",
      "len(speed) : 8608\n",
      "len lon:  8608\n",
      "len lat: 8608\n",
      "inner prods 8608\n",
      "Load 8608\n",
      "dump 8608\n",
      "datetime 8608\n",
      "machine id 16\n",
      "meters from last act 8607\n",
      "len(speed) : 4268\n",
      "len lon:  4268\n",
      "len lat: 4268\n",
      "inner prods 4268\n",
      "Load 4268\n",
      "dump 4268\n",
      "datetime 4268\n",
      "machine id 8\n",
      "meters from last act 4267\n",
      "len(speed) : 5615\n",
      "len lon:  5615\n",
      "len lat: 5615\n",
      "inner prods 5615\n",
      "Load 5615\n",
      "dump 5615\n",
      "datetime 5615\n",
      "machine id 28\n",
      "meters from last act 5614\n",
      "len(speed) : 4226\n",
      "len lon:  4226\n",
      "len lat: 4226\n",
      "inner prods 4226\n",
      "Load 4226\n",
      "dump 4226\n",
      "datetime 4226\n",
      "machine id 4\n",
      "meters from last act 4225\n",
      "len(speed) : 207\n",
      "len lon:  207\n",
      "len lat: 207\n",
      "inner prods 207\n",
      "Load 207\n",
      "dump 207\n",
      "datetime 207\n",
      "machine id 34\n",
      "meters from last act 206\n",
      "len(speed) : 549\n",
      "len lon:  549\n",
      "len lat: 549\n",
      "inner prods 549\n",
      "Load 549\n",
      "dump 549\n",
      "datetime 549\n",
      "machine id 29\n",
      "meters from last act 548\n",
      "len(speed) : 9614\n",
      "len lon:  9614\n",
      "len lat: 9614\n",
      "inner prods 9614\n",
      "Load 9614\n",
      "dump 9614\n",
      "datetime 9614\n",
      "machine id 22\n",
      "meters from last act 9613\n",
      "len(speed) : 8455\n",
      "len lon:  8455\n",
      "len lat: 8455\n",
      "inner prods 8455\n",
      "Load 8455\n",
      "dump 8455\n",
      "datetime 8455\n",
      "machine id 1\n",
      "meters from last act 8454\n",
      "len(speed) : 9822\n",
      "len lon:  9822\n",
      "len lat: 9822\n",
      "inner prods 9822\n",
      "Load 9822\n",
      "dump 9822\n",
      "datetime 9822\n",
      "machine id 40\n",
      "meters from last act 9821\n",
      "len(speed) : 9972\n",
      "len lon:  9972\n",
      "len lat: 9972\n",
      "inner prods 9972\n",
      "Load 9972\n",
      "dump 9972\n",
      "datetime 9972\n",
      "machine id 25\n",
      "meters from last act 9971\n",
      "len(speed) : 8416\n",
      "len lon:  8416\n",
      "len lat: 8416\n",
      "inner prods 8416\n",
      "Load 8416\n",
      "dump 8416\n",
      "datetime 8416\n",
      "machine id 26\n",
      "meters from last act 8415\n",
      "len(speed) : 8390\n",
      "len lon:  8390\n",
      "len lat: 8390\n",
      "inner prods 8390\n",
      "Load 8390\n",
      "dump 8390\n",
      "datetime 8390\n",
      "machine id 16\n",
      "meters from last act 8389\n",
      "len(speed) : 9448\n",
      "len lon:  9448\n",
      "len lat: 9448\n",
      "inner prods 9448\n",
      "Load 9448\n",
      "dump 9448\n",
      "datetime 9448\n",
      "machine id 38\n",
      "meters from last act 9447\n",
      "len(speed) : 10269\n",
      "len lon:  10269\n",
      "len lat: 10269\n",
      "inner prods 10269\n",
      "Load 10269\n",
      "dump 10269\n",
      "datetime 10269\n",
      "machine id 15\n",
      "meters from last act 10268\n",
      "len(speed) : 9688\n",
      "len lon:  9688\n",
      "len lat: 9688\n",
      "inner prods 9688\n",
      "Load 9688\n",
      "dump 9688\n",
      "datetime 9688\n",
      "machine id 30\n",
      "meters from last act 9687\n",
      "len(speed) : 11129\n",
      "len lon:  11129\n",
      "len lat: 11129\n",
      "inner prods 11129\n",
      "Load 11129\n",
      "dump 11129\n",
      "datetime 11129\n",
      "machine id 44\n",
      "meters from last act 11128\n",
      "len(speed) : 11733\n",
      "len lon:  11733\n",
      "len lat: 11733\n",
      "inner prods 11733\n",
      "Load 11733\n",
      "dump 11733\n",
      "datetime 11733\n",
      "machine id 24\n",
      "meters from last act 11732\n",
      "len(speed) : 7872\n",
      "len lon:  7872\n",
      "len lat: 7872\n",
      "inner prods 7872\n",
      "Load 7872\n",
      "dump 7872\n",
      "datetime 7872\n",
      "machine id 20\n",
      "meters from last act 7871\n",
      "len(speed) : 9536\n",
      "len lon:  9536\n",
      "len lat: 9536\n",
      "inner prods 9536\n",
      "Load 9536\n",
      "dump 9536\n",
      "datetime 9536\n",
      "machine id 13\n",
      "meters from last act 9535\n",
      "len(speed) : 5287\n",
      "len lon:  5287\n",
      "len lat: 5287\n",
      "inner prods 5287\n",
      "Load 5287\n",
      "dump 5287\n",
      "datetime 5287\n",
      "machine id 5\n",
      "meters from last act 5286\n",
      "len(speed) : 3033\n",
      "len lon:  3033\n",
      "len lat: 3033\n",
      "inner prods 3033\n",
      "Load 3033\n",
      "dump 3033\n",
      "datetime 3033\n",
      "machine id 34\n",
      "meters from last act 3032\n",
      "len(speed) : 9507\n",
      "len lon:  9507\n",
      "len lat: 9507\n",
      "inner prods 9507\n",
      "Load 9507\n",
      "dump 9507\n",
      "datetime 9507\n",
      "machine id 11\n",
      "meters from last act 9506\n",
      "len(speed) : 8624\n",
      "len lon:  8624\n",
      "len lat: 8624\n",
      "inner prods 8624\n",
      "Load 8624\n",
      "dump 8624\n",
      "datetime 8624\n",
      "machine id 52\n",
      "meters from last act 8623\n",
      "len(speed) : 425\n",
      "len lon:  425\n",
      "len lat: 425\n",
      "inner prods 425\n",
      "Load 425\n",
      "dump 425\n",
      "datetime 425\n",
      "machine id 2\n",
      "meters from last act 424\n",
      "len(speed) : 6318\n",
      "len lon:  6318\n",
      "len lat: 6318\n",
      "inner prods 6318\n",
      "Load 6318\n",
      "dump 6318\n",
      "datetime 6318\n",
      "machine id 4\n",
      "meters from last act 6317\n",
      "len(speed) : 453\n",
      "len lon:  453\n",
      "len lat: 453\n",
      "inner prods 453\n",
      "Load 453\n",
      "dump 453\n",
      "datetime 453\n",
      "machine id 8\n",
      "meters from last act 452\n",
      "len(speed) : 2540\n",
      "len lon:  2540\n",
      "len lat: 2540\n",
      "inner prods 2540\n",
      "Load 2540\n",
      "dump 2540\n",
      "datetime 2540\n",
      "machine id 46\n",
      "meters from last act 2539\n",
      "len(speed) : 1959\n",
      "len lon:  1959\n",
      "len lat: 1959\n",
      "inner prods 1959\n",
      "Load 1959\n",
      "dump 1959\n",
      "datetime 1959\n",
      "machine id 49\n",
      "meters from last act 1958\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "days = [csv_file.split(\".csv\")[0] for csv_file in os.listdir(\"data/GPSData/trips\")]\n",
    "machine_type = \"Truck\"\n",
    "\n",
    "def save_dfs_with_ml_data() -> None:\n",
    "    \"\"\"\n",
    "    Get all the wanted data (speed, vector) for all vehicles at all days\n",
    "    \"\"\"\n",
    "    df_training = pd.DataFrame()\n",
    "    for day in days[:3]:\n",
    "        df_each_day = pd.read_csv(f\"data/GPSData/tripsInfo/{day}.csv\")\n",
    "        df_each_day = df_each_day[df_each_day[\"MachineType\"] == machine_type]  # get trucks only\n",
    "        for idx, unique_vehicle in enumerate(df_each_day[\"DumperMachineNumber\"].unique()):\n",
    "            trip = dataloader.TripsLoader(day)\n",
    "\n",
    "            machine_of_interest = trip._machines[unique_vehicle]\n",
    "            automated_for_given_machine = automated_load_dump_for_machine(machine_of_interest)\n",
    "            automated_for_given_machine.predict()\n",
    "            # automated_for_given_machine.time_plot()\n",
    "            # automated_for_given_machine.gantt_plot()\n",
    "            df_vehicle = automated_for_given_machine.get_df_with_ml_data()\n",
    "            df_training = pd.concat([df_training, df_vehicle], axis=0)\n",
    "              # we only want one vehicle for now\n",
    "    df_training.dropna(inplace=True)\n",
    "    df_training.to_csv(\"data/ml_model_data/training_data/3_days_all_trucks.csv\", sep=',', index=False)\n",
    "    \n",
    "\n",
    "save_dfs_with_ml_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Todo\n",
    "#   Create a summary report on trips and similar\n",
    "#       Could be plots, metrics and statistics\n",
    "#   Improve prediction\n",
    "#   Classify type of errors, some are due to lack of gps signal, will be difficult to fix\n",
    "#   Improve vector creation, maybe current minus 30 seconds, instead of fixed 30 timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
